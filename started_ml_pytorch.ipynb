{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c846d2de",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df2d3a",
   "metadata": {},
   "source": [
    "### How does this lab work ?\n",
    "\n",
    "The lab uses MNIST datasets. The dataset has over 60.000 images of hand written digits. The data will be partitioned between training the AI model and testing the AI model after training.\n",
    "\n",
    "The main steps in  this project include:\n",
    "\n",
    "1. Download the MNIST dataset and create a DataLoader for the dataset.\n",
    "2. Define an AI model to recognize a hand written the MNIST dataset.\n",
    "3. Train the defined AI model using training data from the MNIST dataset.\n",
    "4. Test the trained AI model using testing data from the MNIST dataset.\n",
    "5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e0ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128\n",
      "<module 'torch.nn' from '/home/machine01/.cache/pypoetry/virtualenvs/cognitiveclass-computer-vision-hands-on-wi-KamljRSP-py3.11/lib/python3.11/site-packages/torch/nn/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d66cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78acf9",
   "metadata": {},
   "source": [
    "# Download Dataset adn Create Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac043ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Size 60032\n",
      "Validation data Size 10048\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y torch.Size([64]) torch.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "valid_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "BATCH_SIZE: int = 64\n",
    "\n",
    "train_dataloader: DataLoader = DataLoader(training_data, batch_size=BATCH_SIZE)\n",
    "valid_dataloader: DataLoader = DataLoader(\n",
    "    valid_data, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Training data Size \"\n",
    "    f\"{len(train_dataloader) * BATCH_SIZE}\"\n",
    ")\n",
    "print(\n",
    "    \"Validation data Size \"\n",
    "    f\"{len(valid_dataloader) * BATCH_SIZE}\"\n",
    ")\n",
    "\n",
    "for X, y in valid_dataloader:\n",
    "    print(\n",
    "        f\"Shape of X [N, C, H, W]: {X.shape}\\n\"\n",
    "        f\"Shape of y {y.shape} {y.dtype}\"\n",
    "    )\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff1d7b",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "\n",
    "\n",
    "We first determine the best device for perfoming training with cpu as the default device.\n",
    "\n",
    "We the define the AI model as a Neural Network with 3 layers: an input layer, a hiddern layer,  and an output layer. Between the layers, we use a ReLU activation function.\n",
    "\n",
    "Since the input images are 1X28x28 tensors, we need to flatten the input tensors into a 784 element tensor using the Flatten module before passing the input into our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79859ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device  =  torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Using {device} device\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45663987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)(-)\n"
     ]
    }
   ],
   "source": [
    "# Define a model\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_classes\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                input_size, hidden_size\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                hidden_size, hidden_size\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                hidden_size, num_classes\n",
    "            ),\n",
    "\n",
    "        )\n",
    "    def forward(\n",
    "        self,\n",
    "        image_tensor\n",
    "    ):\n",
    "        image_tensor = self.flatten(image_tensor)\n",
    "        logits = self.linear_relu_stack(image_tensor)\n",
    "        return logits\n",
    "\n",
    "\n",
    "INPUT_SIZE = 28*28\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "print('(-)'*30)\n",
    "print(\n",
    "    model\n",
    ")\n",
    "print('(-)'*30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebededbc",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005efc0",
   "metadata": {},
   "source": [
    "We implement a training function to use with the train_dataloader to train our model. Each iteration over the dataloader returns a batch_size image data tensor along with the expected output. After moving the tensors to the device, we call the forward pass of our model, computer the prediction error using the expected output and then call the backwards pass to compute the gradients and apply them to the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a4e7f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitiveclass-computer-vision-hands-on-wi-KamljRSP-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
